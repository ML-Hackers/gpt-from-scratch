model_name: gpt2
max_seq_length: 256
max_steps: 15000
logging_steps: 1
eval_steps: 100
save_steps: 500
bf16: True
packing: False
output_dir: "outputs/gpt2"
per_device_train_batch_size: 1
gradient_accumulation_steps: 2
dataset_text_field: "text"
use_peft_lora: True
use_gradient_checkpointing: False
use_flash_attn: True
